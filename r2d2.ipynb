{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TC_SentimentAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeYu7+GS47m02NmyN/nphA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/GAIP_22_June/blob/main/r2d2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSVJr5TNFgKp"
      },
      "outputs": [],
      "source": [
        "# Lifecycle\n",
        "\n",
        "# Read the input\n",
        "# preprocess the input\n",
        "# design multiple networks \n",
        "#### 1 design and multiple HP\n",
        "#### diff designs!!!\n",
        "# each design and HP combination- MODEL_N\n",
        "# TRAIN, SCORE/TEST, VAL/EVAL \n",
        "# Select the best model\n",
        "# EXPORT the model for deployment (Docker and Kubernetes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDB - movie reviews\n",
        "# TF - scrapped (web crawling/spyder) - HTML reviews \n",
        "# that are cleaned up!\n"
      ],
      "metadata": {
        "id": "3HEoA-eucjdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Keras - Library wrapper on top of TF so that you don't have to \n",
        "#       - write TF programs! TF is just 1 of the backends!\n",
        "#       - TF, NLTK, Theanos \n",
        "# keras - API inside tensorflow making our LIFE easier \n",
        "#       - prepopulated NN functions\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I6tPUSFpdQcC",
        "outputId": "d9cab7a2-79d2-4d36-c6a1-e6d7c824f7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = keras.datasets.imdb"
      ],
      "metadata": {
        "id": "AZZy_B99dt8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NO idea \n",
        "# 2 approaches\n",
        "# 1) open the dataset as dictionary\n",
        "# 2) open the dataset as folder/directory!\n",
        "# ALL possible functions and properties offered by the class obj!\n"
      ],
      "metadata": {
        "id": "9Mb6y8yRd9bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__dict__\n",
        "# Approach 1- dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrWzEyHeeLfI",
        "outputId": "7b81eee7-3452-43f1-b9c7-d0bb60e5a91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__builtins__': {'ArithmeticError': ArithmeticError,\n",
              "  'AssertionError': AssertionError,\n",
              "  'AttributeError': AttributeError,\n",
              "  'BaseException': BaseException,\n",
              "  'BlockingIOError': BlockingIOError,\n",
              "  'BrokenPipeError': BrokenPipeError,\n",
              "  'BufferError': BufferError,\n",
              "  'BytesWarning': BytesWarning,\n",
              "  'ChildProcessError': ChildProcessError,\n",
              "  'ConnectionAbortedError': ConnectionAbortedError,\n",
              "  'ConnectionError': ConnectionError,\n",
              "  'ConnectionRefusedError': ConnectionRefusedError,\n",
              "  'ConnectionResetError': ConnectionResetError,\n",
              "  'DeprecationWarning': DeprecationWarning,\n",
              "  'EOFError': EOFError,\n",
              "  'Ellipsis': Ellipsis,\n",
              "  'EnvironmentError': OSError,\n",
              "  'Exception': Exception,\n",
              "  'False': False,\n",
              "  'FileExistsError': FileExistsError,\n",
              "  'FileNotFoundError': FileNotFoundError,\n",
              "  'FloatingPointError': FloatingPointError,\n",
              "  'FutureWarning': FutureWarning,\n",
              "  'GeneratorExit': GeneratorExit,\n",
              "  'IOError': OSError,\n",
              "  'ImportError': ImportError,\n",
              "  'ImportWarning': ImportWarning,\n",
              "  'IndentationError': IndentationError,\n",
              "  'IndexError': IndexError,\n",
              "  'InterruptedError': InterruptedError,\n",
              "  'IsADirectoryError': IsADirectoryError,\n",
              "  'KeyError': KeyError,\n",
              "  'KeyboardInterrupt': KeyboardInterrupt,\n",
              "  'LookupError': LookupError,\n",
              "  'MemoryError': MemoryError,\n",
              "  'ModuleNotFoundError': ModuleNotFoundError,\n",
              "  'NameError': NameError,\n",
              "  'None': None,\n",
              "  'NotADirectoryError': NotADirectoryError,\n",
              "  'NotImplemented': NotImplemented,\n",
              "  'NotImplementedError': NotImplementedError,\n",
              "  'OSError': OSError,\n",
              "  'OverflowError': OverflowError,\n",
              "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
              "  'PermissionError': PermissionError,\n",
              "  'ProcessLookupError': ProcessLookupError,\n",
              "  'RecursionError': RecursionError,\n",
              "  'ReferenceError': ReferenceError,\n",
              "  'ResourceWarning': ResourceWarning,\n",
              "  'RuntimeError': RuntimeError,\n",
              "  'RuntimeWarning': RuntimeWarning,\n",
              "  'StopAsyncIteration': StopAsyncIteration,\n",
              "  'StopIteration': StopIteration,\n",
              "  'SyntaxError': SyntaxError,\n",
              "  'SyntaxWarning': SyntaxWarning,\n",
              "  'SystemError': SystemError,\n",
              "  'SystemExit': SystemExit,\n",
              "  'TabError': TabError,\n",
              "  'TimeoutError': TimeoutError,\n",
              "  'True': True,\n",
              "  'TypeError': TypeError,\n",
              "  'UnboundLocalError': UnboundLocalError,\n",
              "  'UnicodeDecodeError': UnicodeDecodeError,\n",
              "  'UnicodeEncodeError': UnicodeEncodeError,\n",
              "  'UnicodeError': UnicodeError,\n",
              "  'UnicodeTranslateError': UnicodeTranslateError,\n",
              "  'UnicodeWarning': UnicodeWarning,\n",
              "  'UserWarning': UserWarning,\n",
              "  'ValueError': ValueError,\n",
              "  'Warning': Warning,\n",
              "  'ZeroDivisionError': ZeroDivisionError,\n",
              "  '__IPYTHON__': True,\n",
              "  '__build_class__': <function __build_class__>,\n",
              "  '__debug__': True,\n",
              "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
              "  '__import__': <function __import__>,\n",
              "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
              "  '__name__': 'builtins',\n",
              "  '__package__': '',\n",
              "  '__pybind11_internals_v3_gcc_libstdcpp_cxxabi1002__': <capsule object NULL at 0x7f48cf298480>,\n",
              "  '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1011__': <capsule object NULL at 0x7f491f1bbbd0>,\n",
              "  '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1013__': <capsule object NULL at 0x7f48beb28f60>,\n",
              "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>),\n",
              "  'abs': <function abs>,\n",
              "  'all': <function all>,\n",
              "  'any': <function any>,\n",
              "  'ascii': <function ascii>,\n",
              "  'bin': <function bin>,\n",
              "  'bool': bool,\n",
              "  'breakpoint': <function breakpoint>,\n",
              "  'bytearray': bytearray,\n",
              "  'bytes': bytes,\n",
              "  'callable': <function callable>,\n",
              "  'chr': <function chr>,\n",
              "  'classmethod': classmethod,\n",
              "  'compile': <function compile>,\n",
              "  'complex': complex,\n",
              "  'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 2000 BeOpen.com.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
              "  All Rights Reserved.,\n",
              "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
              "      for supporting Python development.  See www.python.org for more information.,\n",
              "  'delattr': <function delattr>,\n",
              "  'dict': dict,\n",
              "  'dir': <function dir>,\n",
              "  'display': <function IPython.core.display.display>,\n",
              "  'divmod': <function divmod>,\n",
              "  'dreload': <function IPython.lib.deepreload._dreload>,\n",
              "  'enumerate': enumerate,\n",
              "  'eval': <function eval>,\n",
              "  'exec': <function exec>,\n",
              "  'execfile': <function _pydev_imps._pydev_execfile.execfile>,\n",
              "  'filter': filter,\n",
              "  'float': float,\n",
              "  'format': <function format>,\n",
              "  'frozenset': frozenset,\n",
              "  'get_ipython': <bound method InteractiveShell.get_ipython of <google.colab._shell.Shell object at 0x7f492d5e7810>>,\n",
              "  'getattr': <function getattr>,\n",
              "  'globals': <function globals>,\n",
              "  'hasattr': <function hasattr>,\n",
              "  'hash': <function hash>,\n",
              "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
              "  'hex': <function hex>,\n",
              "  'id': <function id>,\n",
              "  'input': <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7f492cdc7a90>>,\n",
              "  'int': int,\n",
              "  'isinstance': <function isinstance>,\n",
              "  'issubclass': <function issubclass>,\n",
              "  'iter': <function iter>,\n",
              "  'len': <function len>,\n",
              "  'license': Type license() to see the full license text,\n",
              "  'list': list,\n",
              "  'locals': <function locals>,\n",
              "  'map': map,\n",
              "  'max': <function max>,\n",
              "  'memoryview': memoryview,\n",
              "  'min': <function min>,\n",
              "  'next': <function next>,\n",
              "  'object': object,\n",
              "  'oct': <function oct>,\n",
              "  'open': <function io.open>,\n",
              "  'ord': <function ord>,\n",
              "  'pow': <function pow>,\n",
              "  'print': <function print>,\n",
              "  'property': property,\n",
              "  'range': range,\n",
              "  'repr': <function repr>,\n",
              "  'reversed': reversed,\n",
              "  'round': <function round>,\n",
              "  'runfile': <function _pydev_bundle.pydev_umd.runfile>,\n",
              "  'set': set,\n",
              "  'setattr': <function setattr>,\n",
              "  'slice': slice,\n",
              "  'sorted': <function sorted>,\n",
              "  'staticmethod': staticmethod,\n",
              "  'str': str,\n",
              "  'sum': <function sum>,\n",
              "  'super': super,\n",
              "  'tuple': tuple,\n",
              "  'type': type,\n",
              "  'vars': <function vars>,\n",
              "  'zip': zip},\n",
              " '__cached__': '/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/imdb/__pycache__/__init__.cpython-37.pyc',\n",
              " '__doc__': 'Public API for tf.keras.datasets.imdb namespace.\\n',\n",
              " '__file__': '/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/imdb/__init__.py',\n",
              " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x7f489e8e00d0>,\n",
              " '__name__': 'keras.api._v2.keras.datasets.imdb',\n",
              " '__package__': 'keras.api._v2.keras.datasets.imdb',\n",
              " '__path__': ['/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/imdb'],\n",
              " '__spec__': ModuleSpec(name='keras.api._v2.keras.datasets.imdb', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f489e8e00d0>, origin='/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/imdb/__init__.py', submodule_search_locations=['/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/imdb']),\n",
              " '_sys': <module 'sys' (built-in)>,\n",
              " 'get_word_index': <function keras.datasets.imdb.get_word_index>,\n",
              " 'load_data': <function keras.datasets.imdb.load_data>}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Approach 2\n",
        "dir(dataset)\n",
        "# __name__ indicates a predefined inherited function "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjHj8OrBePOI",
        "outputId": "ca6f233a-9f36-4c28-9ef7-3ee5a8ae4882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_sys',\n",
              " 'get_word_index',\n",
              " 'load_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 things- get_word_index, load_data \n",
        "# functions, variables?\n",
        "# dictionary tells us\n",
        "# get_word_index': <function keras.datasets.imdb.get_word_index>,\n",
        "# 'load_data': <function keras.datasets.imdb.load_data>}"
      ],
      "metadata": {
        "id": "-2KLj1FYenEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 functions- load_data and get_word_index!"
      ],
      "metadata": {
        "id": "UR7obfp3fCio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xyz = keras.datasets\n",
        "dir(xyz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z86qFvsfLQm",
        "outputId": "8407256e-0864-4e98-ba6d-ec9eb7c02277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_sys',\n",
              " 'boston_housing',\n",
              " 'cifar10',\n",
              " 'cifar100',\n",
              " 'fashion_mnist',\n",
              " 'imdb',\n",
              " 'mnist',\n",
              " 'reuters']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = dataset.get_word_index()\n",
        "all_data = dataset.load_data()"
      ],
      "metadata": {
        "id": "QKB6BZ7FfOkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15e49c0-f78a-450e-82a0-3f7e09e57bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZkDyftBfmww",
        "outputId": "5e657e6e-81f6-4c92-905a-9c6f3941e7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34701,\n",
              " 'tsukino': 52006,\n",
              " 'nunnery': 52007,\n",
              " 'sonja': 16816,\n",
              " 'vani': 63951,\n",
              " 'woods': 1408,\n",
              " 'spiders': 16115,\n",
              " 'hanging': 2345,\n",
              " 'woody': 2289,\n",
              " 'trawling': 52008,\n",
              " \"hold's\": 52009,\n",
              " 'comically': 11307,\n",
              " 'localized': 40830,\n",
              " 'disobeying': 30568,\n",
              " \"'royale\": 52010,\n",
              " \"harpo's\": 40831,\n",
              " 'canet': 52011,\n",
              " 'aileen': 19313,\n",
              " 'acurately': 52012,\n",
              " \"diplomat's\": 52013,\n",
              " 'rickman': 25242,\n",
              " 'arranged': 6746,\n",
              " 'rumbustious': 52014,\n",
              " 'familiarness': 52015,\n",
              " \"spider'\": 52016,\n",
              " 'hahahah': 68804,\n",
              " \"wood'\": 52017,\n",
              " 'transvestism': 40833,\n",
              " \"hangin'\": 34702,\n",
              " 'bringing': 2338,\n",
              " 'seamier': 40834,\n",
              " 'wooded': 34703,\n",
              " 'bravora': 52018,\n",
              " 'grueling': 16817,\n",
              " 'wooden': 1636,\n",
              " 'wednesday': 16818,\n",
              " \"'prix\": 52019,\n",
              " 'altagracia': 34704,\n",
              " 'circuitry': 52020,\n",
              " 'crotch': 11585,\n",
              " 'busybody': 57766,\n",
              " \"tart'n'tangy\": 52021,\n",
              " 'burgade': 14129,\n",
              " 'thrace': 52023,\n",
              " \"tom's\": 11038,\n",
              " 'snuggles': 52025,\n",
              " 'francesco': 29114,\n",
              " 'complainers': 52027,\n",
              " 'templarios': 52125,\n",
              " '272': 40835,\n",
              " '273': 52028,\n",
              " 'zaniacs': 52130,\n",
              " '275': 34706,\n",
              " 'consenting': 27631,\n",
              " 'snuggled': 40836,\n",
              " 'inanimate': 15492,\n",
              " 'uality': 52030,\n",
              " 'bronte': 11926,\n",
              " 'errors': 4010,\n",
              " 'dialogs': 3230,\n",
              " \"yomada's\": 52031,\n",
              " \"madman's\": 34707,\n",
              " 'dialoge': 30585,\n",
              " 'usenet': 52033,\n",
              " 'videodrome': 40837,\n",
              " \"kid'\": 26338,\n",
              " 'pawed': 52034,\n",
              " \"'girlfriend'\": 30569,\n",
              " \"'pleasure\": 52035,\n",
              " \"'reloaded'\": 52036,\n",
              " \"kazakos'\": 40839,\n",
              " 'rocque': 52037,\n",
              " 'mailings': 52038,\n",
              " 'brainwashed': 11927,\n",
              " 'mcanally': 16819,\n",
              " \"tom''\": 52039,\n",
              " 'kurupt': 25243,\n",
              " 'affiliated': 21905,\n",
              " 'babaganoosh': 52040,\n",
              " \"noe's\": 40840,\n",
              " 'quart': 40841,\n",
              " 'kids': 359,\n",
              " 'uplifting': 5034,\n",
              " 'controversy': 7093,\n",
              " 'kida': 21906,\n",
              " 'kidd': 23379,\n",
              " \"error'\": 52041,\n",
              " 'neurologist': 52042,\n",
              " 'spotty': 18510,\n",
              " 'cobblers': 30570,\n",
              " 'projection': 9878,\n",
              " 'fastforwarding': 40842,\n",
              " 'sters': 52043,\n",
              " \"eggar's\": 52044,\n",
              " 'etherything': 52045,\n",
              " 'gateshead': 40843,\n",
              " 'airball': 34708,\n",
              " 'unsinkable': 25244,\n",
              " 'stern': 7180,\n",
              " \"cervi's\": 52046,\n",
              " 'dnd': 40844,\n",
              " 'dna': 11586,\n",
              " 'insecurity': 20598,\n",
              " \"'reboot'\": 52047,\n",
              " 'trelkovsky': 11037,\n",
              " 'jaekel': 52048,\n",
              " 'sidebars': 52049,\n",
              " \"sforza's\": 52050,\n",
              " 'distortions': 17633,\n",
              " 'mutinies': 52051,\n",
              " 'sermons': 30602,\n",
              " '7ft': 40846,\n",
              " 'boobage': 52052,\n",
              " \"o'bannon's\": 52053,\n",
              " 'populations': 23380,\n",
              " 'chulak': 52054,\n",
              " 'mesmerize': 27633,\n",
              " 'quinnell': 52055,\n",
              " 'yahoo': 10307,\n",
              " 'meteorologist': 52057,\n",
              " 'beswick': 42577,\n",
              " 'boorman': 15493,\n",
              " 'voicework': 40847,\n",
              " \"ster'\": 52058,\n",
              " 'blustering': 22922,\n",
              " 'hj': 52059,\n",
              " 'intake': 27634,\n",
              " 'morally': 5621,\n",
              " 'jumbling': 40849,\n",
              " 'bowersock': 52060,\n",
              " \"'porky's'\": 52061,\n",
              " 'gershon': 16821,\n",
              " 'ludicrosity': 40850,\n",
              " 'coprophilia': 52062,\n",
              " 'expressively': 40851,\n",
              " \"india's\": 19500,\n",
              " \"post's\": 34710,\n",
              " 'wana': 52063,\n",
              " 'wang': 5283,\n",
              " 'wand': 30571,\n",
              " 'wane': 25245,\n",
              " 'edgeways': 52321,\n",
              " 'titanium': 34711,\n",
              " 'pinta': 40852,\n",
              " 'want': 178,\n",
              " 'pinto': 30572,\n",
              " 'whoopdedoodles': 52065,\n",
              " 'tchaikovsky': 21908,\n",
              " 'travel': 2103,\n",
              " \"'victory'\": 52066,\n",
              " 'copious': 11928,\n",
              " 'gouge': 22433,\n",
              " \"chapters'\": 52067,\n",
              " 'barbra': 6702,\n",
              " 'uselessness': 30573,\n",
              " \"wan'\": 52068,\n",
              " 'assimilated': 27635,\n",
              " 'petiot': 16116,\n",
              " 'most\\x85and': 52069,\n",
              " 'dinosaurs': 3930,\n",
              " 'wrong': 352,\n",
              " 'seda': 52070,\n",
              " 'stollen': 52071,\n",
              " 'sentencing': 34712,\n",
              " 'ouroboros': 40853,\n",
              " 'assimilates': 40854,\n",
              " 'colorfully': 40855,\n",
              " 'glenne': 27636,\n",
              " 'dongen': 52072,\n",
              " 'subplots': 4760,\n",
              " 'kiloton': 52073,\n",
              " 'chandon': 23381,\n",
              " \"effect'\": 34713,\n",
              " 'snugly': 27637,\n",
              " 'kuei': 40856,\n",
              " 'welcomed': 9092,\n",
              " 'dishonor': 30071,\n",
              " 'concurrence': 52075,\n",
              " 'stoicism': 23382,\n",
              " \"guys'\": 14896,\n",
              " \"beroemd'\": 52077,\n",
              " 'butcher': 6703,\n",
              " \"melfi's\": 40857,\n",
              " 'aargh': 30623,\n",
              " 'playhouse': 20599,\n",
              " 'wickedly': 11308,\n",
              " 'fit': 1180,\n",
              " 'labratory': 52078,\n",
              " 'lifeline': 40859,\n",
              " 'screaming': 1927,\n",
              " 'fix': 4287,\n",
              " 'cineliterate': 52079,\n",
              " 'fic': 52080,\n",
              " 'fia': 52081,\n",
              " 'fig': 34714,\n",
              " 'fmvs': 52082,\n",
              " 'fie': 52083,\n",
              " 'reentered': 52084,\n",
              " 'fin': 30574,\n",
              " 'doctresses': 52085,\n",
              " 'fil': 52086,\n",
              " 'zucker': 12606,\n",
              " 'ached': 31931,\n",
              " 'counsil': 52088,\n",
              " 'paterfamilias': 52089,\n",
              " 'songwriter': 13885,\n",
              " 'shivam': 34715,\n",
              " 'hurting': 9654,\n",
              " 'effects': 299,\n",
              " 'slauther': 52090,\n",
              " \"'flame'\": 52091,\n",
              " 'sommerset': 52092,\n",
              " 'interwhined': 52093,\n",
              " 'whacking': 27638,\n",
              " 'bartok': 52094,\n",
              " 'barton': 8775,\n",
              " 'frewer': 21909,\n",
              " \"fi'\": 52095,\n",
              " 'ingrid': 6192,\n",
              " 'stribor': 30575,\n",
              " 'approporiately': 52096,\n",
              " 'wobblyhand': 52097,\n",
              " 'tantalisingly': 52098,\n",
              " 'ankylosaurus': 52099,\n",
              " 'parasites': 17634,\n",
              " 'childen': 52100,\n",
              " \"jenkins'\": 52101,\n",
              " 'metafiction': 52102,\n",
              " 'golem': 17635,\n",
              " 'indiscretion': 40860,\n",
              " \"reeves'\": 23383,\n",
              " \"inamorata's\": 57781,\n",
              " 'brittannica': 52104,\n",
              " 'adapt': 7916,\n",
              " \"russo's\": 30576,\n",
              " 'guitarists': 48246,\n",
              " 'abbott': 10553,\n",
              " 'abbots': 40861,\n",
              " 'lanisha': 17649,\n",
              " 'magickal': 40863,\n",
              " 'mattter': 52105,\n",
              " \"'willy\": 52106,\n",
              " 'pumpkins': 34716,\n",
              " 'stuntpeople': 52107,\n",
              " 'estimate': 30577,\n",
              " 'ugghhh': 40864,\n",
              " 'gameplay': 11309,\n",
              " \"wern't\": 52108,\n",
              " \"n'sync\": 40865,\n",
              " 'sickeningly': 16117,\n",
              " 'chiara': 40866,\n",
              " 'disturbed': 4011,\n",
              " 'portmanteau': 40867,\n",
              " 'ineffectively': 52109,\n",
              " \"duchonvey's\": 82143,\n",
              " \"nasty'\": 37519,\n",
              " 'purpose': 1285,\n",
              " 'lazers': 52112,\n",
              " 'lightened': 28105,\n",
              " 'kaliganj': 52113,\n",
              " 'popularism': 52114,\n",
              " \"damme's\": 18511,\n",
              " 'stylistics': 30578,\n",
              " 'mindgaming': 52115,\n",
              " 'spoilerish': 46449,\n",
              " \"'corny'\": 52117,\n",
              " 'boerner': 34718,\n",
              " 'olds': 6792,\n",
              " 'bakelite': 52118,\n",
              " 'renovated': 27639,\n",
              " 'forrester': 27640,\n",
              " \"lumiere's\": 52119,\n",
              " 'gaskets': 52024,\n",
              " 'needed': 884,\n",
              " 'smight': 34719,\n",
              " 'master': 1297,\n",
              " \"edie's\": 25905,\n",
              " 'seeber': 40868,\n",
              " 'hiya': 52120,\n",
              " 'fuzziness': 52121,\n",
              " 'genesis': 14897,\n",
              " 'rewards': 12607,\n",
              " 'enthrall': 30579,\n",
              " \"'about\": 40869,\n",
              " \"recollection's\": 52122,\n",
              " 'mutilated': 11039,\n",
              " 'fatherlands': 52123,\n",
              " \"fischer's\": 52124,\n",
              " 'positively': 5399,\n",
              " '270': 34705,\n",
              " 'ahmed': 34720,\n",
              " 'zatoichi': 9836,\n",
              " 'bannister': 13886,\n",
              " 'anniversaries': 52127,\n",
              " \"helm's\": 30580,\n",
              " \"'work'\": 52128,\n",
              " 'exclaimed': 34721,\n",
              " \"'unfunny'\": 52129,\n",
              " '274': 52029,\n",
              " 'feeling': 544,\n",
              " \"wanda's\": 52131,\n",
              " 'dolan': 33266,\n",
              " '278': 52133,\n",
              " 'peacoat': 52134,\n",
              " 'brawny': 40870,\n",
              " 'mishra': 40871,\n",
              " 'worlders': 40872,\n",
              " 'protags': 52135,\n",
              " 'skullcap': 52136,\n",
              " 'dastagir': 57596,\n",
              " 'affairs': 5622,\n",
              " 'wholesome': 7799,\n",
              " 'hymen': 52137,\n",
              " 'paramedics': 25246,\n",
              " 'unpersons': 52138,\n",
              " 'heavyarms': 52139,\n",
              " 'affaire': 52140,\n",
              " 'coulisses': 52141,\n",
              " 'hymer': 40873,\n",
              " 'kremlin': 52142,\n",
              " 'shipments': 30581,\n",
              " 'pixilated': 52143,\n",
              " \"'00s\": 30582,\n",
              " 'diminishing': 18512,\n",
              " 'cinematic': 1357,\n",
              " 'resonates': 14898,\n",
              " 'simplify': 40874,\n",
              " \"nature'\": 40875,\n",
              " 'temptresses': 40876,\n",
              " 'reverence': 16822,\n",
              " 'resonated': 19502,\n",
              " 'dailey': 34722,\n",
              " '2\\x85': 52144,\n",
              " 'treize': 27641,\n",
              " 'majo': 52145,\n",
              " 'kiya': 21910,\n",
              " 'woolnough': 52146,\n",
              " 'thanatos': 39797,\n",
              " 'sandoval': 35731,\n",
              " 'dorama': 40879,\n",
              " \"o'shaughnessy\": 52147,\n",
              " 'tech': 4988,\n",
              " 'fugitives': 32018,\n",
              " 'teck': 30583,\n",
              " \"'e'\": 76125,\n",
              " 'doesn’t': 40881,\n",
              " 'purged': 52149,\n",
              " 'saying': 657,\n",
              " \"martians'\": 41095,\n",
              " 'norliss': 23418,\n",
              " 'dickey': 27642,\n",
              " 'dicker': 52152,\n",
              " \"'sependipity\": 52153,\n",
              " 'padded': 8422,\n",
              " 'ordell': 57792,\n",
              " \"sturges'\": 40882,\n",
              " 'independentcritics': 52154,\n",
              " 'tempted': 5745,\n",
              " \"atkinson's\": 34724,\n",
              " 'hounded': 25247,\n",
              " 'apace': 52155,\n",
              " 'clicked': 15494,\n",
              " \"'humor'\": 30584,\n",
              " \"martino's\": 17177,\n",
              " \"'supporting\": 52156,\n",
              " 'warmongering': 52032,\n",
              " \"zemeckis's\": 34725,\n",
              " 'lube': 21911,\n",
              " 'shocky': 52157,\n",
              " 'plate': 7476,\n",
              " 'plata': 40883,\n",
              " 'sturgess': 40884,\n",
              " \"nerds'\": 40885,\n",
              " 'plato': 20600,\n",
              " 'plath': 34726,\n",
              " 'platt': 40886,\n",
              " 'mcnab': 52159,\n",
              " 'clumsiness': 27643,\n",
              " 'altogether': 3899,\n",
              " 'massacring': 42584,\n",
              " 'bicenntinial': 52160,\n",
              " 'skaal': 40887,\n",
              " 'droning': 14360,\n",
              " 'lds': 8776,\n",
              " 'jaguar': 21912,\n",
              " \"cale's\": 34727,\n",
              " 'nicely': 1777,\n",
              " 'mummy': 4588,\n",
              " \"lot's\": 18513,\n",
              " 'patch': 10086,\n",
              " 'kerkhof': 50202,\n",
              " \"leader's\": 52161,\n",
              " \"'movie\": 27644,\n",
              " 'uncomfirmed': 52162,\n",
              " 'heirloom': 40888,\n",
              " 'wrangle': 47360,\n",
              " 'emotion\\x85': 52163,\n",
              " \"'stargate'\": 52164,\n",
              " 'pinoy': 40889,\n",
              " 'conchatta': 40890,\n",
              " 'broeke': 41128,\n",
              " 'advisedly': 40891,\n",
              " \"barker's\": 17636,\n",
              " 'descours': 52166,\n",
              " 'lots': 772,\n",
              " 'lotr': 9259,\n",
              " 'irs': 9879,\n",
              " 'lott': 52167,\n",
              " 'xvi': 40892,\n",
              " 'irk': 34728,\n",
              " 'irl': 52168,\n",
              " 'ira': 6887,\n",
              " 'belzer': 21913,\n",
              " 'irc': 52169,\n",
              " 'ire': 27645,\n",
              " 'requisites': 40893,\n",
              " 'discipline': 7693,\n",
              " 'lyoko': 52961,\n",
              " 'extend': 11310,\n",
              " 'nature': 873,\n",
              " \"'dickie'\": 52170,\n",
              " 'optimist': 40894,\n",
              " 'lapping': 30586,\n",
              " 'superficial': 3900,\n",
              " 'vestment': 52171,\n",
              " 'extent': 2823,\n",
              " 'tendons': 52172,\n",
              " \"heller's\": 52173,\n",
              " 'quagmires': 52174,\n",
              " 'miyako': 52175,\n",
              " 'moocow': 20601,\n",
              " \"coles'\": 52176,\n",
              " 'lookit': 40895,\n",
              " 'ravenously': 52177,\n",
              " 'levitating': 40896,\n",
              " 'perfunctorily': 52178,\n",
              " 'lookin': 30587,\n",
              " \"lot'\": 40898,\n",
              " 'lookie': 52179,\n",
              " 'fearlessly': 34870,\n",
              " 'libyan': 52181,\n",
              " 'fondles': 40899,\n",
              " 'gopher': 35714,\n",
              " 'wearying': 40901,\n",
              " \"nz's\": 52182,\n",
              " 'minuses': 27646,\n",
              " 'puposelessly': 52183,\n",
              " 'shandling': 52184,\n",
              " 'decapitates': 31268,\n",
              " 'humming': 11929,\n",
              " \"'nother\": 40902,\n",
              " 'smackdown': 21914,\n",
              " 'underdone': 30588,\n",
              " 'frf': 40903,\n",
              " 'triviality': 52185,\n",
              " 'fro': 25248,\n",
              " 'bothers': 8777,\n",
              " \"'kensington\": 52186,\n",
              " 'much': 73,\n",
              " 'muco': 34730,\n",
              " 'wiseguy': 22615,\n",
              " \"richie's\": 27648,\n",
              " 'tonino': 40904,\n",
              " 'unleavened': 52187,\n",
              " 'fry': 11587,\n",
              " \"'tv'\": 40905,\n",
              " 'toning': 40906,\n",
              " 'obese': 14361,\n",
              " 'sensationalized': 30589,\n",
              " 'spiv': 40907,\n",
              " 'spit': 6259,\n",
              " 'arkin': 7364,\n",
              " 'charleton': 21915,\n",
              " 'jeon': 16823,\n",
              " 'boardroom': 21916,\n",
              " 'doubts': 4989,\n",
              " 'spin': 3084,\n",
              " 'hepo': 53083,\n",
              " 'wildcat': 27649,\n",
              " 'venoms': 10584,\n",
              " 'misconstrues': 52191,\n",
              " 'mesmerising': 18514,\n",
              " 'misconstrued': 40908,\n",
              " 'rescinds': 52192,\n",
              " 'prostrate': 52193,\n",
              " 'majid': 40909,\n",
              " 'climbed': 16479,\n",
              " 'canoeing': 34731,\n",
              " 'majin': 52195,\n",
              " 'animie': 57804,\n",
              " 'sylke': 40910,\n",
              " 'conditioned': 14899,\n",
              " 'waddell': 40911,\n",
              " '3\\x85': 52196,\n",
              " 'hyperdrive': 41188,\n",
              " 'conditioner': 34732,\n",
              " 'bricklayer': 53153,\n",
              " 'hong': 2576,\n",
              " 'memoriam': 52198,\n",
              " 'inventively': 30592,\n",
              " \"levant's\": 25249,\n",
              " 'portobello': 20638,\n",
              " 'remand': 52200,\n",
              " 'mummified': 19504,\n",
              " 'honk': 27650,\n",
              " 'spews': 19505,\n",
              " 'visitations': 40912,\n",
              " 'mummifies': 52201,\n",
              " 'cavanaugh': 25250,\n",
              " 'zeon': 23385,\n",
              " \"jungle's\": 40913,\n",
              " 'viertel': 34733,\n",
              " 'frenchmen': 27651,\n",
              " 'torpedoes': 52202,\n",
              " 'schlessinger': 52203,\n",
              " 'torpedoed': 34734,\n",
              " 'blister': 69876,\n",
              " 'cinefest': 52204,\n",
              " 'furlough': 34735,\n",
              " 'mainsequence': 52205,\n",
              " 'mentors': 40914,\n",
              " 'academic': 9094,\n",
              " 'stillness': 20602,\n",
              " 'academia': 40915,\n",
              " 'lonelier': 52206,\n",
              " 'nibby': 52207,\n",
              " \"losers'\": 52208,\n",
              " 'cineastes': 40916,\n",
              " 'corporate': 4449,\n",
              " 'massaging': 40917,\n",
              " 'bellow': 30593,\n",
              " 'absurdities': 19506,\n",
              " 'expetations': 53241,\n",
              " 'nyfiken': 40918,\n",
              " 'mehras': 75638,\n",
              " 'lasse': 52209,\n",
              " 'visability': 52210,\n",
              " 'militarily': 33946,\n",
              " \"elder'\": 52211,\n",
              " 'gainsbourg': 19023,\n",
              " 'hah': 20603,\n",
              " 'hai': 13420,\n",
              " 'haj': 34736,\n",
              " 'hak': 25251,\n",
              " 'hal': 4311,\n",
              " 'ham': 4892,\n",
              " 'duffer': 53259,\n",
              " 'haa': 52213,\n",
              " 'had': 66,\n",
              " 'advancement': 11930,\n",
              " 'hag': 16825,\n",
              " \"hand'\": 25252,\n",
              " 'hay': 13421,\n",
              " 'mcnamara': 20604,\n",
              " \"mozart's\": 52214,\n",
              " 'duffel': 30731,\n",
              " 'haq': 30594,\n",
              " 'har': 13887,\n",
              " 'has': 44,\n",
              " 'hat': 2401,\n",
              " 'hav': 40919,\n",
              " 'haw': 30595,\n",
              " 'figtings': 52215,\n",
              " 'elders': 15495,\n",
              " 'underpanted': 52216,\n",
              " 'pninson': 52217,\n",
              " 'unequivocally': 27652,\n",
              " \"barbara's\": 23673,\n",
              " \"bello'\": 52219,\n",
              " 'indicative': 12997,\n",
              " 'yawnfest': 40920,\n",
              " 'hexploitation': 52220,\n",
              " \"loder's\": 52221,\n",
              " 'sleuthing': 27653,\n",
              " \"justin's\": 32622,\n",
              " \"'ball\": 52222,\n",
              " \"'summer\": 52223,\n",
              " \"'demons'\": 34935,\n",
              " \"mormon's\": 52225,\n",
              " \"laughton's\": 34737,\n",
              " 'debell': 52226,\n",
              " 'shipyard': 39724,\n",
              " 'unabashedly': 30597,\n",
              " 'disks': 40401,\n",
              " 'crowd': 2290,\n",
              " 'crowe': 10087,\n",
              " \"vancouver's\": 56434,\n",
              " 'mosques': 34738,\n",
              " 'crown': 6627,\n",
              " 'culpas': 52227,\n",
              " 'crows': 27654,\n",
              " 'surrell': 53344,\n",
              " 'flowless': 52229,\n",
              " 'sheirk': 52230,\n",
              " \"'three\": 40923,\n",
              " \"peterson'\": 52231,\n",
              " 'ooverall': 52232,\n",
              " 'perchance': 40924,\n",
              " 'bottom': 1321,\n",
              " 'chabert': 53363,\n",
              " 'sneha': 52233,\n",
              " 'inhuman': 13888,\n",
              " 'ichii': 52234,\n",
              " 'ursla': 52235,\n",
              " 'completly': 30598,\n",
              " 'moviedom': 40925,\n",
              " 'raddick': 52236,\n",
              " 'brundage': 51995,\n",
              " 'brigades': 40926,\n",
              " 'starring': 1181,\n",
              " \"'goal'\": 52237,\n",
              " 'caskets': 52238,\n",
              " 'willcock': 52239,\n",
              " \"threesome's\": 52240,\n",
              " \"mosque'\": 52241,\n",
              " \"cover's\": 52242,\n",
              " 'spaceships': 17637,\n",
              " 'anomalous': 40927,\n",
              " 'ptsd': 27655,\n",
              " 'shirdan': 52243,\n",
              " 'obscenity': 21962,\n",
              " 'lemmings': 30599,\n",
              " 'duccio': 30600,\n",
              " \"levene's\": 52244,\n",
              " \"'gorby'\": 52245,\n",
              " \"teenager's\": 25255,\n",
              " 'marshall': 5340,\n",
              " 'honeymoon': 9095,\n",
              " 'shoots': 3231,\n",
              " 'despised': 12258,\n",
              " 'okabasho': 52246,\n",
              " 'fabric': 8289,\n",
              " 'cannavale': 18515,\n",
              " 'raped': 3537,\n",
              " \"tutt's\": 52247,\n",
              " 'grasping': 17638,\n",
              " 'despises': 18516,\n",
              " \"thief's\": 40928,\n",
              " 'rapes': 8926,\n",
              " 'raper': 52248,\n",
              " \"eyre'\": 27656,\n",
              " 'walchek': 52249,\n",
              " \"elmo's\": 23386,\n",
              " 'perfumes': 40929,\n",
              " 'spurting': 21918,\n",
              " \"exposition'\\x85\": 52250,\n",
              " 'denoting': 52251,\n",
              " 'thesaurus': 34740,\n",
              " \"shoot'\": 40930,\n",
              " 'bonejack': 49759,\n",
              " 'simpsonian': 52253,\n",
              " 'hebetude': 30601,\n",
              " \"hallow's\": 34741,\n",
              " 'desperation\\x85': 52254,\n",
              " 'incinerator': 34742,\n",
              " 'congratulations': 10308,\n",
              " 'humbled': 52255,\n",
              " \"else's\": 5924,\n",
              " 'trelkovski': 40845,\n",
              " \"rape'\": 52256,\n",
              " \"'chapters'\": 59386,\n",
              " '1600s': 52257,\n",
              " 'martian': 7253,\n",
              " 'nicest': 25256,\n",
              " 'eyred': 52259,\n",
              " 'passenger': 9457,\n",
              " 'disgrace': 6041,\n",
              " 'moderne': 52260,\n",
              " 'barrymore': 5120,\n",
              " 'yankovich': 52261,\n",
              " 'moderns': 40931,\n",
              " 'studliest': 52262,\n",
              " 'bedsheet': 52263,\n",
              " 'decapitation': 14900,\n",
              " 'slurring': 52264,\n",
              " \"'nunsploitation'\": 52265,\n",
              " \"'character'\": 34743,\n",
              " 'cambodia': 9880,\n",
              " 'rebelious': 52266,\n",
              " 'pasadena': 27657,\n",
              " 'crowne': 40932,\n",
              " \"'bedchamber\": 52267,\n",
              " 'conjectural': 52268,\n",
              " 'appologize': 52269,\n",
              " 'halfassing': 52270,\n",
              " 'paycheque': 57816,\n",
              " 'palms': 20606,\n",
              " \"'islands\": 52271,\n",
              " 'hawked': 40933,\n",
              " 'palme': 21919,\n",
              " 'conservatively': 40934,\n",
              " 'larp': 64007,\n",
              " 'palma': 5558,\n",
              " 'smelling': 21920,\n",
              " 'aragorn': 12998,\n",
              " 'hawker': 52272,\n",
              " 'hawkes': 52273,\n",
              " 'explosions': 3975,\n",
              " 'loren': 8059,\n",
              " \"pyle's\": 52274,\n",
              " 'shootout': 6704,\n",
              " \"mike's\": 18517,\n",
              " \"driscoll's\": 52275,\n",
              " 'cogsworth': 40935,\n",
              " \"britian's\": 52276,\n",
              " 'childs': 34744,\n",
              " \"portrait's\": 52277,\n",
              " 'chain': 3626,\n",
              " 'whoever': 2497,\n",
              " 'puttered': 52278,\n",
              " 'childe': 52279,\n",
              " 'maywether': 52280,\n",
              " 'chair': 3036,\n",
              " \"rance's\": 52281,\n",
              " 'machu': 34745,\n",
              " 'ballet': 4517,\n",
              " 'grapples': 34746,\n",
              " 'summerize': 76152,\n",
              " 'freelance': 30603,\n",
              " \"andrea's\": 52283,\n",
              " '\\x91very': 52284,\n",
              " 'coolidge': 45879,\n",
              " 'mache': 18518,\n",
              " 'balled': 52285,\n",
              " 'grappled': 40937,\n",
              " 'macha': 18519,\n",
              " 'underlining': 21921,\n",
              " 'macho': 5623,\n",
              " 'oversight': 19507,\n",
              " 'machi': 25257,\n",
              " 'verbally': 11311,\n",
              " 'tenacious': 21922,\n",
              " 'windshields': 40938,\n",
              " 'paychecks': 18557,\n",
              " 'jerk': 3396,\n",
              " \"good'\": 11931,\n",
              " 'prancer': 34748,\n",
              " 'prances': 21923,\n",
              " 'olympus': 52286,\n",
              " 'lark': 21924,\n",
              " 'embark': 10785,\n",
              " 'gloomy': 7365,\n",
              " 'jehaan': 52287,\n",
              " 'turaqui': 52288,\n",
              " \"child'\": 20607,\n",
              " 'locked': 2894,\n",
              " 'pranced': 52289,\n",
              " 'exact': 2588,\n",
              " 'unattuned': 52290,\n",
              " 'minute': 783,\n",
              " 'skewed': 16118,\n",
              " 'hodgins': 40940,\n",
              " 'skewer': 34749,\n",
              " 'think\\x85': 52291,\n",
              " 'rosenstein': 38765,\n",
              " 'helmit': 52292,\n",
              " 'wrestlemanias': 34750,\n",
              " 'hindered': 16826,\n",
              " \"martha's\": 30604,\n",
              " 'cheree': 52293,\n",
              " \"pluckin'\": 52294,\n",
              " 'ogles': 40941,\n",
              " 'heavyweight': 11932,\n",
              " 'aada': 82190,\n",
              " 'chopping': 11312,\n",
              " 'strongboy': 61534,\n",
              " 'hegemonic': 41342,\n",
              " 'adorns': 40942,\n",
              " 'xxth': 41346,\n",
              " 'nobuhiro': 34751,\n",
              " 'capitães': 52298,\n",
              " 'kavogianni': 52299,\n",
              " 'antwerp': 13422,\n",
              " 'celebrated': 6538,\n",
              " 'roarke': 52300,\n",
              " 'baggins': 40943,\n",
              " 'cheeseburgers': 31270,\n",
              " 'matras': 52301,\n",
              " \"nineties'\": 52302,\n",
              " \"'craig'\": 52303,\n",
              " 'celebrates': 12999,\n",
              " 'unintentionally': 3383,\n",
              " 'drafted': 14362,\n",
              " 'climby': 52304,\n",
              " '303': 52305,\n",
              " 'oldies': 18520,\n",
              " 'climbs': 9096,\n",
              " 'honour': 9655,\n",
              " 'plucking': 34752,\n",
              " '305': 30074,\n",
              " 'address': 5514,\n",
              " 'menjou': 40944,\n",
              " \"'freak'\": 42592,\n",
              " 'dwindling': 19508,\n",
              " 'benson': 9458,\n",
              " 'white’s': 52307,\n",
              " 'shamelessness': 40945,\n",
              " 'impacted': 21925,\n",
              " 'upatz': 52308,\n",
              " 'cusack': 3840,\n",
              " \"flavia's\": 37567,\n",
              " 'effette': 52309,\n",
              " 'influx': 34753,\n",
              " 'boooooooo': 52310,\n",
              " 'dimitrova': 52311,\n",
              " 'houseman': 13423,\n",
              " 'bigas': 25259,\n",
              " 'boylen': 52312,\n",
              " 'phillipenes': 52313,\n",
              " 'fakery': 40946,\n",
              " \"grandpa's\": 27658,\n",
              " 'darnell': 27659,\n",
              " 'undergone': 19509,\n",
              " 'handbags': 52315,\n",
              " 'perished': 21926,\n",
              " 'pooped': 37778,\n",
              " 'vigour': 27660,\n",
              " 'opposed': 3627,\n",
              " 'etude': 52316,\n",
              " \"caine's\": 11799,\n",
              " 'doozers': 52317,\n",
              " 'photojournals': 34754,\n",
              " 'perishes': 52318,\n",
              " 'constrains': 34755,\n",
              " 'migenes': 40948,\n",
              " 'consoled': 30605,\n",
              " 'alastair': 16827,\n",
              " 'wvs': 52319,\n",
              " 'ooooooh': 52320,\n",
              " 'approving': 34756,\n",
              " 'consoles': 40949,\n",
              " 'disparagement': 52064,\n",
              " 'futureistic': 52322,\n",
              " 'rebounding': 52323,\n",
              " \"'date\": 52324,\n",
              " 'gregoire': 52325,\n",
              " 'rutherford': 21927,\n",
              " 'americanised': 34757,\n",
              " 'novikov': 82196,\n",
              " 'following': 1042,\n",
              " 'munroe': 34758,\n",
              " \"morita'\": 52326,\n",
              " 'christenssen': 52327,\n",
              " 'oatmeal': 23106,\n",
              " 'fossey': 25260,\n",
              " 'livered': 40950,\n",
              " 'listens': 13000,\n",
              " \"'marci\": 76164,\n",
              " \"otis's\": 52330,\n",
              " 'thanking': 23387,\n",
              " 'maude': 16019,\n",
              " 'extensions': 34759,\n",
              " 'ameteurish': 52332,\n",
              " \"commender's\": 52333,\n",
              " 'agricultural': 27661,\n",
              " 'convincingly': 4518,\n",
              " 'fueled': 17639,\n",
              " 'mahattan': 54014,\n",
              " \"paris's\": 40952,\n",
              " 'vulkan': 52336,\n",
              " 'stapes': 52337,\n",
              " 'odysessy': 52338,\n",
              " 'harmon': 12259,\n",
              " 'surfing': 4252,\n",
              " 'halloran': 23494,\n",
              " 'unbelieveably': 49580,\n",
              " \"'offed'\": 52339,\n",
              " 'quadrant': 30607,\n",
              " 'inhabiting': 19510,\n",
              " 'nebbish': 34760,\n",
              " 'forebears': 40953,\n",
              " 'skirmish': 34761,\n",
              " 'ocassionally': 52340,\n",
              " \"'resist\": 52341,\n",
              " 'impactful': 21928,\n",
              " 'spicier': 52342,\n",
              " 'touristy': 40954,\n",
              " \"'football'\": 52343,\n",
              " 'webpage': 40955,\n",
              " 'exurbia': 52345,\n",
              " 'jucier': 52346,\n",
              " 'professors': 14901,\n",
              " 'structuring': 34762,\n",
              " 'jig': 30608,\n",
              " 'overlord': 40956,\n",
              " 'disconnect': 25261,\n",
              " 'sniffle': 82201,\n",
              " 'slimeball': 40957,\n",
              " 'jia': 40958,\n",
              " 'milked': 16828,\n",
              " 'banjoes': 40959,\n",
              " 'jim': 1237,\n",
              " 'workforces': 52348,\n",
              " 'jip': 52349,\n",
              " 'rotweiller': 52350,\n",
              " 'mundaneness': 34763,\n",
              " \"'ninja'\": 52351,\n",
              " \"dead'\": 11040,\n",
              " \"cipriani's\": 40960,\n",
              " 'modestly': 20608,\n",
              " \"professor'\": 52352,\n",
              " 'shacked': 40961,\n",
              " 'bashful': 34764,\n",
              " 'sorter': 23388,\n",
              " 'overpowering': 16120,\n",
              " 'workmanlike': 18521,\n",
              " 'henpecked': 27662,\n",
              " 'sorted': 18522,\n",
              " \"jōb's\": 52354,\n",
              " \"'always\": 52355,\n",
              " \"'baptists\": 34765,\n",
              " 'dreamcatchers': 52356,\n",
              " \"'silence'\": 52357,\n",
              " 'hickory': 21929,\n",
              " 'fun\\x97yet': 52358,\n",
              " 'breakumentary': 52359,\n",
              " 'didn': 15496,\n",
              " 'didi': 52360,\n",
              " 'pealing': 52361,\n",
              " 'dispite': 40962,\n",
              " \"italy's\": 25262,\n",
              " 'instability': 21930,\n",
              " 'quarter': 6539,\n",
              " 'quartet': 12608,\n",
              " 'padmé': 52362,\n",
              " \"'bleedmedry\": 52363,\n",
              " 'pahalniuk': 52364,\n",
              " 'honduras': 52365,\n",
              " 'bursting': 10786,\n",
              " \"pablo's\": 41465,\n",
              " 'irremediably': 52367,\n",
              " 'presages': 40963,\n",
              " 'bowlegged': 57832,\n",
              " 'dalip': 65183,\n",
              " 'entering': 6260,\n",
              " 'newsradio': 76172,\n",
              " 'presaged': 54150,\n",
              " \"giallo's\": 27663,\n",
              " 'bouyant': 40964,\n",
              " 'amerterish': 52368,\n",
              " 'rajni': 18523,\n",
              " 'leeves': 30610,\n",
              " 'macauley': 34767,\n",
              " 'seriously': 612,\n",
              " 'sugercoma': 52369,\n",
              " 'grimstead': 52370,\n",
              " \"'fairy'\": 52371,\n",
              " 'zenda': 30611,\n",
              " \"'twins'\": 52372,\n",
              " 'realisation': 17640,\n",
              " 'highsmith': 27664,\n",
              " 'raunchy': 7817,\n",
              " 'incentives': 40965,\n",
              " 'flatson': 52374,\n",
              " 'snooker': 35097,\n",
              " 'crazies': 16829,\n",
              " 'crazier': 14902,\n",
              " 'grandma': 7094,\n",
              " 'napunsaktha': 52375,\n",
              " 'workmanship': 30612,\n",
              " 'reisner': 52376,\n",
              " \"sanford's\": 61306,\n",
              " '\\x91doña': 52377,\n",
              " 'modest': 6108,\n",
              " \"everything's\": 19153,\n",
              " 'hamer': 40966,\n",
              " \"couldn't'\": 52379,\n",
              " 'quibble': 13001,\n",
              " 'socking': 52380,\n",
              " 'tingler': 21931,\n",
              " 'gutman': 52381,\n",
              " 'lachlan': 40967,\n",
              " 'tableaus': 52382,\n",
              " 'headbanger': 52383,\n",
              " 'spoken': 2847,\n",
              " 'cerebrally': 34768,\n",
              " \"'road\": 23490,\n",
              " 'tableaux': 21932,\n",
              " \"proust's\": 40968,\n",
              " 'periodical': 40969,\n",
              " \"shoveller's\": 52385,\n",
              " 'tamara': 25263,\n",
              " 'affords': 17641,\n",
              " 'concert': 3249,\n",
              " \"yara's\": 87955,\n",
              " 'someome': 52386,\n",
              " 'lingering': 8424,\n",
              " \"abraham's\": 41511,\n",
              " 'beesley': 34769,\n",
              " 'cherbourg': 34770,\n",
              " 'kagan': 28624,\n",
              " 'snatch': 9097,\n",
              " \"miyazaki's\": 9260,\n",
              " 'absorbs': 25264,\n",
              " \"koltai's\": 40970,\n",
              " 'tingled': 64027,\n",
              " 'crossroads': 19511,\n",
              " 'rehab': 16121,\n",
              " 'falworth': 52389,\n",
              " 'sequals': 52390,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "inspect.getfullargspec(dataset.load_data)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJBzk9p2fqnD",
        "outputId": "2f088cd5-110f-4d8a-b8b7-056ce0946c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['path',\n",
              " 'num_words',\n",
              " 'skip_top',\n",
              " 'maxlen',\n",
              " 'seed',\n",
              " 'start_char',\n",
              " 'oov_char',\n",
              " 'index_from']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = keras.datasets.imdb"
      ],
      "metadata": {
        "id": "yquBMavZf5YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = dataset.get_word_index()\n"
      ],
      "metadata": {
        "id": "IghTShO5gf96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = dataset.load_data(num_words=10000)\n",
        "# every word beyond the 10000 -> UNKNOWN "
      ],
      "metadata": {
        "id": "bBnBxPz-h3nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "240wUI4Igr2O",
        "outputId": "929627d8-63c4-47c2-ae52-3a221092c9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 2, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 8738, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 5421, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 2, 2, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 9909, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 2, 3292, 98, 6, 2, 10, 10, 6639, 19, 14, 2, 267, 162, 711, 37, 5900, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 2, 5437, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 5664, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 7885, 5, 2, 68, 1830, 19, 6571, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 5673, 7, 15, 2, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 6676, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 2, 21, 4, 7298, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 5698, 3406, 718, 2, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6mtSQ4hEoj",
        "outputId": "cf2b933c-e47e-4d58-e3c9-8d6dff4310b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31lJif8FhUj1",
        "outputId": "8ee515e6-ce15-47e1-938e-82db1d3d66f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrhIJlibhdy-",
        "outputId": "a03e10bf-52e2-4f8c-c3c2-23f7b034b3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intutive schema - (x1,y1),(x2,y2)"
      ],
      "metadata": {
        "id": "X_BR69u_hfvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x1,y1),(x2,y2) = dataset.load_data(num_words=10000)\n",
        "# outside the limit of 10k -> UNKNOWN"
      ],
      "metadata": {
        "id": "R9a6BzMTh144"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index[\"hello\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6N0oh_ch-Z4",
        "outputId": "c13b9545-706f-4ccc-ec3d-4d46355f75f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4822"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x1), len(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiKyQdbrkQWy",
        "outputId": "855cdb0e-ce34-4e4a-a897-6c937c1ff766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y1), len(y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmK4YqWVke66",
        "outputId": "3fe317fb-91ea-44fa-b390-101b074c4069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, ytrain = x1, y1\n",
        "xtest, ytest = x2, y2"
      ],
      "metadata": {
        "id": "21zfXrXIkhN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cLwyK8OkquW",
        "outputId": "688a3c6d-5d35-46db-e0de-c384e4b4ae34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <PAD> 0\n",
        "# <START> 1\n",
        "# <UNKNOWN> 2\n",
        "# <UNUSED> 3\n",
        "# "
      ],
      "metadata": {
        "id": "sp1ohKMdktbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index to word instead of word to index!\n",
        "rev_dictionary = {val:element for element,val in word_index.items()}"
      ],
      "metadata": {
        "id": "VEfSbpBuk8Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rev_dictionary[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z7zNaURclKpo",
        "outputId": "7fe01d47-d2a2-47e0-ad69-f0d725894c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"it's\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dwYORDFip-VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(text):\n",
        "  return \" \".join( [ rev_dictionary[wrd] for wrd in text ] )"
      ],
      "metadata": {
        "id": "nBZgPYXkld71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder(xtrain[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "fexzVkKhl0bW",
        "outputId": "1ba9a6c4-e26e-4f06-dc17-a8527ef97be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder(xtrain[17002])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "61Zppiaql3qY",
        "outputId": "593a2e03-3c84-4d14-dc28-63dbbd0ff7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the going field sinatra's to contrary without reality falls michael resolve and sister ways this as thanks their place this results from me will simon's violent american this of mars film of pathetic br decides agent for my and beowulf and of and and route won't comedy ralph numerous in tears of bottom camera old of bland he and to gates this of its blind too i i of you effort film is everett place this of ramones concept film is twin order romance be war to about offer new shirts filmmaker is learn deep in of create blues william stars regard mob refer results to romantic this in of everyone know of lighting strong put i i even focused movie in when involved couple film of duty br of performances whilst in long show of actually carla film whole under haunted and repeating of almost br of grayson offer i i dvd and untrue camera film of and to williams br is and grandfather in so le not immediately missions showed watched mention br cut he seen cuban and decides and there is quite in ii but this 98 as movie is personally fact place felt to of did minutes something responsible of and rush not told scantily task richard of how it is both and few and thats felt film about and group film spoiled making of father is get raj away they about and and film and give set around atmospheric killed us kentucky there is reactions and to give something ever br about working and her an it his head i i loved was big leaving similar decides everyone know based and it judge tim judge it's overall this is and yet br too what poor his first of soon more it director scene they an not but fact beginning more it away that's in and of flat and sat to and guitar br law but hate i i where scenes this think because you of thought simply children's criticized premise and map and story one forth of ever from he and old who of anger whole drab scenes know is motivated yes george this of spoken flashy are wife as and would onto when yet br flashy that it in at coming and to and new and of sf top jan music so tell school this only flashy what as three that's of and it killer's ice man flashy but facing returned mass hollywood this felt\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder([1])\n",
        "# MISTAKE- the is NOT supposed to be 1!\n",
        "# 1 is reserved for <START>!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AujxqcngmWGU",
        "outputId": "42d3c6e9-5067-4e37-cee0-ab433d5b4610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder([2]))\n",
        "print(decoder([3]))\n",
        "# <UNKNOWN> and <UNUSED> are also missing!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxAdJf96ml3t",
        "outputId": "11f0d5b9-20ee-49cb-f452-f166dd36abe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and\n",
            "a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(decoder([0]))\n",
        "# <PAD> doesn't even exist!"
      ],
      "metadata": {
        "id": "9xq_GLyGmwtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_fixed = { wrd:value+3 for wrd, value in word_index.items()}"
      ],
      "metadata": {
        "id": "ZtJ-Wfplm1dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_fixed[\"<PAD>\"] = 0\n",
        "dictionary_fixed[\"<START>\"] = 1\n",
        "dictionary_fixed[\"<UNKNOWN>\"] = 2\n",
        "dictionary_fixed[\"<UNUSED>\"] = 3"
      ],
      "metadata": {
        "id": "tFqgtCj8nHdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dvKeM_EQreH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_2_word = {val:wrd for wrd, val in dictionary_fixed.items()}"
      ],
      "metadata": {
        "id": "20TMOVW_nTeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_fixed(text):\n",
        "  return \" \".join( [ idx_2_word[wrd] for wrd in text ] )"
      ],
      "metadata": {
        "id": "_p6oCnMpnhbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_fixed(xtrain[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "4bNQHWgcnmjw",
        "outputId": "496c568d-b2ee-4e57-d83c-3641f540d35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNKNOWN> is an amazing actor and now the same being director <UNKNOWN> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNKNOWN> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNKNOWN> to the two little boy's that played the <UNKNOWN> of norman and paul they were just brilliant children are often left out of the <UNKNOWN> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_fixed(xtrain[16388])"
      ],
      "metadata": {
        "id": "1h2SOJpmnp02",
        "outputId": "6525b3b8-c86b-4615-f94f-3aae36067a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> from the beginning this movie did have a few flaws the main character played by hayden christensen is a the rich young <UNKNOWN> who has inherited his father's considerable wealth and power and he is struggling to both fill his father's shoes and cut the <UNKNOWN> strings mother and co executive keeps too tight he also has the problem of having a heart condition and waiting in the <UNKNOWN> that is the <UNKNOWN> <UNKNOWN> <UNKNOWN> there are also minor back stories which your first instinct is to mostly ignore that become important later such as his friendship with his surgeon <UNKNOWN> howard and his romance with a middle class girl jessica alba <UNKNOWN> story lines but not bad enough to ruin the movie the only real <UNKNOWN> <UNKNOWN> moment was the name of lena <UNKNOWN> character overbearing woman named <UNKNOWN> subtle br br the <UNKNOWN> scenes are not at all <UNKNOWN> i appreciated that people who find surgery scenes scary might not the horror of being awake during <UNKNOWN> was done well at first you watch in emotional agony as christensen screams <UNKNOWN> through the chest <UNKNOWN> and the <UNKNOWN> <UNKNOWN> the moment of irony from the trailers then comes where while he is one of the unlucky few to be awake during <UNKNOWN> he is also luck in that it helps him learn that his <UNKNOWN> team is planning to murder him br br the big twist however is very predictable and sends the film <UNKNOWN> into the conspiracy and his memories of the little signs which were there but he like us initially missed br br there are two more twists at the end involving his relationship with his mother one is an impressive gesture by <UNKNOWN> which comes of as unimpressive due to poor writing the other is a secret about the family's past which seemed very tacked on and pointless br br the initially well done <UNKNOWN> awareness drama gets lost in the poorly written conspiracy drama there is a one final attempt to bring it back which falls flat taking the entire movie with it\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(xtrain[0]))\n",
        "print(len(xtrain[10]))\n",
        "print(len(xtrain[1000]))"
      ],
      "metadata": {
        "id": "m06g9vNznruY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac92c6a-e15a-4e46-ef1b-3d04f7fff30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "450\n",
            "298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Networks only accept FIXED size inputs!"
      ],
      "metadata": {
        "id": "BKx9sqxKR6R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_padded = keras.preprocessing.sequence.pad_sequences(\n",
        "    xtrain, maxlen=256, padding='post', truncating='post', value=0\n",
        ")"
      ],
      "metadata": {
        "id": "3ERadzKVR_e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(xtrain_padded[0]))\n",
        "print(len(xtrain_padded[10]))\n",
        "print(len(xtrain_padded[1000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgmZ25MmSwOI",
        "outputId": "3a978cbe-6dc6-4bcc-fb7c-24d317b754f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "256\n",
            "256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_padded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfE6no2US1AW",
        "outputId": "f56da7b2-d920-40fb-cf0b-a8e3dda70724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,\n",
              "       4468,   66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,\n",
              "        838,  112,   50,  670,    2,    9,   35,  480,  284,    5,  150,\n",
              "          4,  172,  112,  167,    2,  336,  385,   39,    4,  172, 4536,\n",
              "       1111,   17,  546,   38,   13,  447,    4,  192,   50,   16,    6,\n",
              "        147, 2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,\n",
              "         71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,\n",
              "          4,   22,   17,  515,   17,   12,   16,  626,   18,    2,    5,\n",
              "         62,  386,   12,    8,  316,    8,  106,    5,    4, 2223, 5244,\n",
              "         16,  480,   66, 3785,   33,    4,  130,   12,   16,   38,  619,\n",
              "          5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,    6,\n",
              "         22,   12,  215,   28,   77,   52,    5,   14,  407,   16,   82,\n",
              "          2,    8,    4,  107,  117, 5952,   15,  256,    4,    2,    7,\n",
              "       3766,    5,  723,   36,   71,   43,  530,  476,   26,  400,  317,\n",
              "         46,    7,    4,    2, 1029,   13,  104,   88,    4,  381,   15,\n",
              "        297,   98,   32, 2071,   56,   26,  141,    6,  194, 7486,   18,\n",
              "          4,  226,   22,   21,  134,  476,   26,  480,    5,  144,   30,\n",
              "       5535,   18,   51,   36,   28,  224,   92,   25,  104,    4,  226,\n",
              "         65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
              "        113,  103,   32,   15,   16, 5345,   19,  178,   32,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_fixed(xtrain_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "piG0dCZMS34_",
        "outputId": "e2acb87e-5f11-4926-9f99-22da939a428d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNKNOWN> is an amazing actor and now the same being director <UNKNOWN> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNKNOWN> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNKNOWN> to the two little boy's that played the <UNKNOWN> of norman and paul they were just brilliant children are often left out of the <UNKNOWN> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer gives you a MATRIX\n",
        "# i need to convert MATRIX into a number sequence!!!\n",
        "# Deep Learning ONLY happens on numbers!!!"
      ],
      "metadata": {
        "id": "NiJUH0H3S8jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average of the values!\n",
        "# Embedding (matrix) --- average! (real number)-- pass it to the network!\n"
      ],
      "metadata": {
        "id": "ymwChkEjVlm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass it to network/LEARN\n",
        "# 2 fully connected layers!\n",
        "# final network-> Embedding- GlobalAveragePooling- DenseX2\n",
        "# TensorFlow- fully connected layers are called DENSE layers"
      ],
      "metadata": {
        "id": "prJRI1L4V5Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# POOLING \n",
        "# window size\n",
        "\n",
        "# [ 1 2 3]    ----- MAX pooling (2,2) --- [ 2  3 ]\n",
        "# [ 2 0 1]                                [ 3  2 ]\n",
        "# [ 3 2 1]   ------ Max pooling (1,3). --- [ 3 ]\n",
        "#                                          [ 2 ]  \n",
        "#                                          [ 3 ]\n",
        "# --- average pooling (2,2) --- [ 5/4  3/2]\n",
        "#                           --- [ 7/4  1  ]\n",
        "# AveragePooling2D- blurring "
      ],
      "metadata": {
        "id": "hCnz4nzYWG1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# every layer has to accept whatever previous layer is throwing\n",
        "# at it\n",
        "# INPUT size is ONLY defined in the FIRST layer!\n",
        "layer1 = Embedding(10000, 16) # vectors = 16 X 10000 = 160000\n",
        "layer2 = GlobalAveragePooling1D() # This layer has NO input \n",
        "# or output definition BECAUSE it has only 1 JOB- average!\n",
        "# LEARNING\n",
        "layer3 = Dense(128, activation = keras.activations.relu, \n",
        "               kernel_regularizer= keras.regularizers.L1L2())\n",
        "layer_drop = Dropout(0.2)\n",
        "layer4 = Dense(1, activation=keras.activations.sigmoid) # one for pos, one for neg!\n",
        "# Last layer should decide how many outputs we need!"
      ],
      "metadata": {
        "id": "EyYHiDQnWZ2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([layer1, layer2, layer3, layer_drop,layer4])"
      ],
      "metadata": {
        "id": "iMduxZtLYWHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "# weights = ?\n",
        "# bias = ?\n",
        "# for every output line from the network - we get a BIAS\n",
        "# for every input in the network which is broken into outputs,\n",
        "# we get a weight\n",
        "# weights = input X output \n",
        "# bias = output\n",
        "# total parameters in dense layers = input X output + output\n",
        "# total parameters in embedding layer = input X output\n",
        "# total parameters in GlobalAvgPooling = ?\n",
        "# Embedding is EXACT calculation, hence NO BIAS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6_O2jKvYbH7",
        "outputId": "faa4652e-f86b-46ed-b199-a34def39cd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, None, 16)          160000    \n",
            "                                                                 \n",
            " global_average_pooling1d_10  (None, 16)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               2176      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162,305\n",
            "Trainable params: 162,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "16*128 + 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M56Lkc_6aOsQ",
        "outputId": "6a2fca9a-5023-4ae0-a28c-1140d0490ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2176"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "128*2 + 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rjcE9cbaWqX",
        "outputId": "5a777d37-e070-4dc6-8c01-2fe8dc382173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "258"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test/Evaluate"
      ],
      "metadata": {
        "id": "eFs0Hi0YaZoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layerA = Embedding(10000, 32) # vectors = 16 X 10000 = 160000\n",
        "layerB = GlobalAveragePooling1D() # This layer has NO input \n",
        "# or output definition BECAUSE it has only 1 JOB- average!\n",
        "# LEARNING\n",
        "layerC_1 = Dense(256,activation = keras.activations.relu,\n",
        "                 kernel_regularizer=keras.regularizers.L1L2())\n",
        "layerC_2 = Dense(512,activation = keras.activations.relu,\n",
        "                 kernel_regularizer=keras.regularizers.L1L2())\n",
        "\n",
        "layer_drop = Dropout(0.2)\n",
        "\n",
        "layerD = Dense(1,activation=keras.activations.sigmoid)\n",
        "\n",
        "model2 = keras.models.Sequential([layerA, layerB, layerC_1,layerC_2, layer_drop, layerD])"
      ],
      "metadata": {
        "id": "clXTdm5we0Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKytfyHce_v9",
        "outputId": "d495fd91-1b00-4deb-9ca8-07e9f3916b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, None, 32)          320000    \n",
            "                                                                 \n",
            " global_average_pooling1d_11  (None, 32)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 256)               8448      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 460,545\n",
            "Trainable params: 460,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model2.compile(loss=keras.losses.binary_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aV5HecL0fVOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain_padded, ytrain, epochs=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dARAlSVSfBMz",
        "outputId": "fd15754d-814c-46fb-eead-6456cbcb4a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.4619 - accuracy: 0.7883\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.2541 - accuracy: 0.8999\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.2010 - accuracy: 0.9246\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1682 - accuracy: 0.9384\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1456 - accuracy: 0.9500\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1246 - accuracy: 0.9585\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1077 - accuracy: 0.9662\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0941 - accuracy: 0.9719\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0817 - accuracy: 0.9763\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0718 - accuracy: 0.9796\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0655 - accuracy: 0.9811\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0577 - accuracy: 0.9837\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0496 - accuracy: 0.9858\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0427 - accuracy: 0.9885\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0375 - accuracy: 0.9892\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0359 - accuracy: 0.9890\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0323 - accuracy: 0.9895\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0288 - accuracy: 0.9913\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0261 - accuracy: 0.9912\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0211 - accuracy: 0.9932\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0179 - accuracy: 0.9944\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0155 - accuracy: 0.9954\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9934\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0164 - accuracy: 0.9941\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0142 - accuracy: 0.9950\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0111 - accuracy: 0.9964\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0151 - accuracy: 0.9944\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0178 - accuracy: 0.9937\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0125 - accuracy: 0.9955\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0102 - accuracy: 0.9966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f489ac742d0>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(xtrain_padded, ytrain, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Oy0lZZfKx4",
        "outputId": "ee238b22-57e8-4bed-ffff-edbd66a25ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3805 - accuracy: 0.8194\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2213 - accuracy: 0.9148\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1770 - accuracy: 0.9356\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1456 - accuracy: 0.9468\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1214 - accuracy: 0.9562\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0982 - accuracy: 0.9642\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0806 - accuracy: 0.9681\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0627 - accuracy: 0.9736\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0520 - accuracy: 0.9785\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.0422 - accuracy: 0.9836\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0349 - accuracy: 0.9870\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.0326 - accuracy: 0.9874\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.0302 - accuracy: 0.9887\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.0229 - accuracy: 0.9915\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0204 - accuracy: 0.9926\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0222 - accuracy: 0.9920\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0156 - accuracy: 0.9945\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0167 - accuracy: 0.9941\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0171 - accuracy: 0.9935\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0151 - accuracy: 0.9941\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0111 - accuracy: 0.9964\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0110 - accuracy: 0.9956\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0199 - accuracy: 0.9934\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0131 - accuracy: 0.9955\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0062 - accuracy: 0.9980\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0099 - accuracy: 0.9968\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0105 - accuracy: 0.9962\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0116 - accuracy: 0.9958\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0102 - accuracy: 0.9967\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0062 - accuracy: 0.9980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f489ac549d0>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest_padded = keras.preprocessing.sequence.pad_sequences(\n",
        "    xtest, maxlen=256, padding='post', truncating='post', value=0\n",
        ")"
      ],
      "metadata": {
        "id": "l0PXJOpZfT1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = model.predict(xtest_padded)\n",
        "p2 = model2.predict(xtest_padded)"
      ],
      "metadata": {
        "id": "39aZu5r7hCBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(p1[:5])\n",
        "print('***')\n",
        "print(p2[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii9VFmz8hJTJ",
        "outputId": "d27b8849-38df-4a49-cd8a-f91a49378c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.6285094e-06]\n",
            " [1.0000000e+00]\n",
            " [4.8648431e-05]\n",
            " [9.9853766e-01]\n",
            " [9.9999011e-01]]\n",
            "***\n",
            "[[6.4014275e-05]\n",
            " [1.0000000e+00]\n",
            " [9.2006373e-01]\n",
            " [9.9939346e-01]\n",
            " [1.0000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TichGUgkhMSS",
        "outputId": "108c415d-528e-49aa-d89b-b9a1e9a0d0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT has to be scaled so that our tests can be compared!\n",
        "# SIGMOID-> Logloss/Probability\n"
      ],
      "metadata": {
        "id": "7PEz6HuthP6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logic_transcoding = lambda x: 1 if x>0.5 else 0\n",
        "r1 = [ logic_transcoding(result) for result in p1]\n",
        "r2 = [ logic_transcoding(result) for result in p2]"
      ],
      "metadata": {
        "id": "Du6x-JewjvNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgMfS0Tsj8KS",
        "outputId": "09354ac4-fa76-45f0-a81e-205662a462a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEzZIK7IkY7V",
        "outputId": "55725be1-cb47-45c1-b46d-b3986ce5a139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(r1, ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUlcz1yrkaaW",
        "outputId": "7bc795fc-3970-44bb-90f9-b8f38697f758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81524"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(r2, ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyB_kt-0kfJu",
        "outputId": "e2704964-22cc-4251-df7b-55dfd1bbeb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83628"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dealing with overfitting \n",
        "\n",
        "# Don't teach everything!\n",
        "# 1) DROPOUT\n",
        "# \n",
        "# Regularization\n",
        "# 2) L1/L2/L1L2"
      ],
      "metadata": {
        "id": "EsBccHnFkonX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}